{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e795b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df81fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>The impact of AI on society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>The future of renewable energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>The role of space exploration in modern science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>,Will robots replace human jobs?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                            topic\n",
       "0  1001                      The impact of AI on society\n",
       "1  1002                   The future of renewable energy\n",
       "2  1003  The role of space exploration in modern science\n",
       "3  1005                 ,Will robots replace human jobs?"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test dataset\n",
    "df = pd.read_excel(\"kaggletest.csv.xlsx\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5adf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f85002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class EssayGenerationEnv(gym.Env):\n",
    "    def __init__(self, topics):\n",
    "        super(EssayGenerationEnv, self).__init__()\n",
    "        \n",
    "        self.topics = topics  # List of topics\n",
    "        self.current_idx = 0  # Track current essay index\n",
    "        \n",
    "        # Define action space (generated essay, encoded as tokens)\n",
    "        self.action_space = spaces.Discrete(50257)  # GPT-2 token count\n",
    "        \n",
    "        # Define state space (essay topic)\n",
    "        self.observation_space = spaces.Discrete(len(self.topics))\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment and return the next topic\"\"\"\n",
    "        self.current_idx = 0\n",
    "        return self.topics[self.current_idx]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action (generate essay) and compute reward\"\"\"\n",
    "        \n",
    "        # Decode token IDs back into text (simulated essay)\n",
    "        essay = tokenizer.decode(action)\n",
    "        \n",
    "        # Simulate LLM judge scores (replace this with real API later)\n",
    "        score_variance = np.random.uniform(0.5, 3.0)  # Simulating disagreement\n",
    "        \n",
    "        # Compute reward (maximize variance)\n",
    "        reward = score_variance  \n",
    "\n",
    "        # Move to next topic\n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= len(self.topics)\n",
    "        \n",
    "        next_state = self.topics[self.current_idx] if not done else None\n",
    "        \n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "# Load topics\n",
    "topics = df[\"topic\"].tolist()\n",
    "\n",
    "# Create environment\n",
    "env = EssayGenerationEnv(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf503d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e85ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedbed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PPOAgent(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(PPOAgent, self).__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=5e-5)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"Generate text using the model\"\"\"\n",
    "        output = self.model.generate(input_ids, max_length=100)\n",
    "        return output\n",
    "\n",
    "    def compute_loss(self, old_probs, new_probs, rewards):\n",
    "        \"\"\"PPO loss function\"\"\"\n",
    "        ratio = torch.exp(new_probs - old_probs)\n",
    "        clip_adv = torch.clamp(ratio, 0.8, 1.2) * rewards\n",
    "        loss = -torch.min(ratio * rewards, clip_adv).mean()\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, old_probs, new_probs, rewards):\n",
    "        \"\"\"Optimize the policy\"\"\"\n",
    "        loss = self.compute_loss(old_probs, new_probs, rewards)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "# Initialize agent\n",
    "agent = PPOAgent(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac3ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e402c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -1.4371, Reward: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -2.6970, Reward: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -1.3262, Reward: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -1.1783, Reward: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -2.7487, Reward: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -1.6760, Reward: 1.68\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Convert topic to tokenized input\n",
    "        input_ids = tokenizer.encode(state, return_tensors=\"pt\")\n",
    "        \n",
    "        # Generate essay\n",
    "        with torch.no_grad():\n",
    "            action = agent(input_ids).squeeze().tolist()  # Ensure action is a list\n",
    "        \n",
    "        # Get new probabilities (for loss function)\n",
    "        new_probs = torch.log(torch.tensor(1.0))  # Placeholder\n",
    "        \n",
    "        # Simulate reward (variance)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Compute PPO loss and update model\n",
    "        old_probs = new_probs.clone()\n",
    "        reward_tensor = torch.tensor(float(reward), requires_grad=True)  # ✅ Fix applied here\n",
    "        loss = agent.train_step(old_probs, new_probs, reward_tensor)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}, Reward: {reward:.2f}\")\n",
    "        \n",
    "        state = next_state if not done else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52222fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = []\n",
    "for topic in topics:\n",
    "    input_ids = tokenizer.encode(topic, return_tensors=\"pt\")\n",
    "    output = agent(input_ids)\n",
    "    essay = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    essays.append(essay)\n",
    "\n",
    "# Save results\n",
    "df[\"essay\"] = essays\n",
    "df[[\"id\", \"essay\"]].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a299cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
